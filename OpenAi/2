import gymnasium as gym
import torch
from algo.gradMC import QPolicy
env = gym.make("LunarLander-v3", render_mode="human")

observation, info = env.reset(seed=42)

policy = QPolicy(8, 4)
epsilon = 0.3
states = [observation]
actions = []
rewards = []
gamma = 1
alpha = 1


for _ in range(1000):

    q = policy(torch.from_numpy(observation))
    action = torch.randint(0,4, (1,)).item()

    if torch.randn(1,)[0] > epsilon:
        action = torch.argmax(q).item()

    actions.append(q[action])
    print(action)
    observation, reward, terminated, truncated, info = env.step(action)
    rewards.append(reward)
    states.append(observation)

    if terminated or truncated:
        G_t = 0
        for t in range(len(states) - 2, -1, -1):

            policy.zero_grad()
            G_t = rewards[t] + gamma * G_t
            loss = 0.5 * (G_t - actions[t])**2
            loss.backward()

            for p in policy.parameters():
               p.weight -= alpha * p.grad

        states  = []
        actions = []
        rewards = []

        observation, info = env.reset()
        states.append(observation)


env.close()
